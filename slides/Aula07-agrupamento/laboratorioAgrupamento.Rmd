Laboratório sobre algoritmos de clustering
========================================================
**Professor Fabrício J. Barth**

Introdução
----------
O objetivo deste laboratório é exercitar os conceitos vistos em sala de aula utilizando a **ferramenta R**.
O primeiro exercício irá utilizar o datataset sobre a planta [Iris](http://archive.ics.uci.edu/ml/datasets/Iris). O R já vem com este dataset, portanto basta digitar o comando abaixo.

```{r}
data(iris)
```

O dataset é formado por 4 atributos e uma classe:

````{r}
head(iris)
````

O algoritmo K-means é implementado na função **kmeans**. Se quisermos identificar dois clusters no dataset
iris, basta digitar:

````{r}
modelCluster <- kmeans(iris[,1:4], centers=2)
modelCluster
````

A execução do algoritmo kmeans levou em consideração apenas os atributos números (excluímos a classe).
O resultado pode também ser visualizado na forma de plot:

```{r fig.width=7, fig.height=6}
plot(iris$Sepal.Length, iris$Sepal.Width, pch=21, bg=c("red", "green")[modelCluster$cluster])
```

Podemos também visualizar todos os atributos: 

```{r fig.width=7, fig.height=6}
plot(iris[,1:4], pch=21, bg=c("red", "green")[modelCluster$cluster])
```

No entanto, será que este é o número de cluster mais adequados? Para implementar a análise **elbow** podemos utilizar a seguinte função:

````{r}
elbow <- function(dataset){
  wss <- numeric(15)
  for (i in 1:15) 
    wss[i] <- sum(kmeans(dataset,centers=i, nstart=100)$withinss)
  plot(1:15, wss, type="b", main="Elbow method", xlab="Number of Clusters",ylab="Within groups sum of squares", pch=8)
}
````

E utilizá-la com o dataset iris:

````{r}
elbow(iris[,1:4])
````

A partir desta análise é possível verificar que o número ideal de cluters é 3. Depois disso, podemos imprimir apresentando os clusters de forma visual em conjunto com os seus centros.

````{r}
clusterModel <- kmeans(iris[,1:4], centers=3, nstart=100)
plot(iris[,1], iris[,2], col = clusterModel$cluster, pch=19)
points(clusterModel$centers, col = 1:3, pch=19,cex=2,lwd=3)
````

Exercício com dados sobre abalos sísmicos
-----------------------------------------

Para iniciar este exercício, nós vamos capturar os dados deste endereço Web:

````{r}
#fileUrl <- "http://earthquake.usgs.gov/earthquakes/catalogs/eqs7day-M1.txt"
#download.file(fileUrl,destfile="earthquakeData.csv",method="curl") 
#dateDownloaded <- date() - Wed Apr 10 22:50:58 2013
eData <- read.csv("earthquakeData.csv")
````

Quais são os atributos? Qual é a dimensão do dataset? Quais são os tipos dos atributos?

````{r}
names(eData)
dim(eData)
sapply(eData,class)
````

Vamos utilizar os atributos _magnitude_ e _depth_ para identificar abalos sísmicos similares.

````{r}
summary(eData$Magnitude)
summary(eData$Depth)
````

Pode-se perceber que a amplitude destas variáveis é bem diferente. Para que possamos utilizar um algoritmo de clustering sobre estas variáveis é necessário normaliza-las.

````{r}
eData$MagnitudeNorm <- eData$Magnitude / max(eData$Magnitude)
eData$DepthNorm <- eData$Depth / max(eData$Depth)
````

Levando-se em consideração os dois novos atributos, podemos determinar o número de clusters adequado:

````{r}
elbow(eData[,11:12])
````

Podemos considerar que o número de clusters mais adequado é 4.

````{r fig.width=8, fig.height=6}
set.seed(1234)
clusterModel <- kmeans(eData[,11:12], centers=4, nstart=100)
#par(mfrow=c(1,2))
plot(eData[,11], eData[,12], col = clusterModel$cluster, pch=19, xlab="Magnitude", ylab="Depth", main="Clusters de abalos sísmicos (Wed Apr 10 22:50:58 2013)")
points(clusterModel$centers, col = 1:4, pch=19,cex=2,lwd=3)

plot(eData[,7], eData[,8], col = clusterModel$cluster, pch=19, xlab="Magnitude", ylab="Depth", main="Clusters de abalos sísmicos - valores originais")
#points(clusterModel$centers, col = 1:4, pch=19,cex=2,lwd=3)
clusterModel
````

Quem são os pontos vermelhos?

````{r}
eData[clusterModel$cluster == 1, ]
````

Lembrando que este experimento foi executado em: Wed Apr 10 22:50:58 2013 segundo o conteúdo que está na variável dateDownloaded.

Fazendo a mesma análise no local de maior incidência de abalos sísmicos
-------------------------------------------------------------------------

````{r}
maiorIncidencia <- as.data.frame(table(eData$Region))
maiorIncidencia <- subset(maiorIncidencia, maiorIncidencia$Freq > 100)
maiorIncidencia

dataset <- subset(eData, eData$Region == 'Southern California')
````

**Qual é a seqüência de etapas que devem ser realizadas para analisar os clusters dos abalos sísmicos da região de _Southern California_?**
